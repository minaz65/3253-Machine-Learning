{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Environment (conda_tensorflow2)",
      "language": "python",
      "name": "conda_tensorflow2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "W11_EX1_fashion_mnist.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP0mz4DPFzQC"
      },
      "source": [
        "# Exercise Objective:\n",
        "\n",
        "Build an image classifier in Keras that detects fashion items from low res images. The training set contains 60,000 grayscale images, each 28x28 pixels. There are 10 classes, all different clothes items.\n",
        "\n",
        "In this work, you need to:\n",
        "\n",
        "__Exercise 1__\n",
        "1. Train a sequential, fully connected neural net to classify the clothes.\n",
        "2. Assess the performance.\n",
        "\n",
        "__Exercise 2__\n",
        "3. Train a sequential, convolutional neural net to classify the clothes.\n",
        "4. Compare the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaPIjKwkFzQD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rejVxys8FzQH"
      },
      "source": [
        "Let's start by loading the fashion mnist dataset as we did back in week 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU4bsPw_FzQH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "2c7dee35-f077-444d-a46d-f67fc9ff0b3d"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Iy8A3zFzQK"
      },
      "source": [
        "Let's make sure the input pixel data is float64. We'll also split off some validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LruwzuxFzQL"
      },
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydd1QiE9FzQO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "185bb39e-786e-4ea1-ccf2-c0c19e2c994f"
      },
      "source": [
        "X_train.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3UakPwXFzQQ"
      },
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VeneTsHFzQT"
      },
      "source": [
        "Let's see what the data looks like. Rerun to see more examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFrfb4OWFzQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "3ff990bd-e214-4f07-b373-fcebccd47de9"
      },
      "source": [
        "rand_idx = np.random.choice(range(X_train.shape[0]))\n",
        "plt.imshow(X_train[rand_idx], cmap=\"binary\")\n",
        "plt.colorbar()\n",
        "plt.axis('off')\n",
        "plt.title(class_names[y_train[rand_idx]]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAD9CAYAAABjhbg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8waNfh6FzQX"
      },
      "source": [
        "## Exercise 1\n",
        "Build the dense model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGFSlZkBFzQY"
      },
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZN4ScjKFzQa"
      },
      "source": [
        "img_size = (28, 28)\n",
        "n_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft88X5Z5FzQd"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "model = ## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_7JCM3r7FzQf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjSTsa7MFzQi"
      },
      "source": [
        "learning_rate = 0.005\n",
        "n_epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O08iEigZFzQl"
      },
      "source": [
        "from tensorflow.keras.optimizers import ## YOUR CODE HERE ##\n",
        "\n",
        "optimizer = ## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57aKCI7-FzQo"
      },
      "source": [
        "# Hint: sparse_categorical_crossentropy is a good loss fn for softmax\n",
        "model.compile(## YOUR CODE HERE ##)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPKU_fnIFzQq"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "save_cb = ModelCheckpoint(## YOUR CODE HERE ##)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zhMTjIsOFzQs"
      },
      "source": [
        "history = model.fit(## YOUR CODE HERE ##)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQyJka3dFzQv"
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beK9IRi5FzQy"
      },
      "source": [
        "Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xZwukfAFzQz"
      },
      "source": [
        "y_hat = ## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ULR0QWoUFzQ1"
      },
      "source": [
        "def plot_prediction():\n",
        "    rand_idx = np.random.choice(range(X_test.shape[0]))\n",
        "    image = X_test[rand_idx].squeeze()\n",
        "    prediction = class_names[y_hat[rand_idx]]\n",
        "    actual = class_names[y_test[rand_idx]]\n",
        "\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Prediction: {prediction} (Actual: {actual})\")\n",
        "\n",
        "plot_prediction()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTZfG__LFzQ5"
      },
      "source": [
        "from sklearn.metrics import ## YOUR CODE HERE ##\n",
        "\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "romB8IznFzQ7"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "__NOTE:__\n",
        "It is important to add a channel dimension to images going into convolutions, even if that dimension is simply 1 (greyscale). You can unsqueeze the numpy array like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSe5JrjmFzQ8"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuUoeR7IFzQ-"
      },
      "source": [
        "X_train = X_train[..., None]\n",
        "X_valid = X_valid[..., None]\n",
        "X_test = X_test[..., None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkDtjbzQFzRA"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUTW3ZXLFzRC"
      },
      "source": [
        "Build the convolutional model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHcbbnZ9FzRD"
      },
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUvzU5B2FzRF"
      },
      "source": [
        "img_size = (28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9ysrKfXFzRI"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "model = ## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhwdm6MpFzRK"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMkQiswAFzRM"
      },
      "source": [
        "model.compile(## YOUR CODE HERE ##)\n",
        "\n",
        "save_cb = ModelCheckpoint(## YOUR CODE HERE ##)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LCam9a8rFzRO"
      },
      "source": [
        "history = model.fit(## YOUR CODE HERE ##)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWvqn8JQFzRQ"
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRyoRdfyFzRS"
      },
      "source": [
        "Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bULx7rEFzRT"
      },
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4zMJOavFzRV"
      },
      "source": [
        "y_hat = ## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fB7aLDfFzRX"
      },
      "source": [
        "plot_prediction()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWgT463FFzRZ"
      },
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}